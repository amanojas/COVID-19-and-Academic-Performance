<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aman Desai">
<meta name="dcterms.date" content="2025-11-23">
<meta name="keywords" content="COVID-19">

<title>Effects of COVID-19 on the Academic Performance of College Students</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="01_journal_submission_files/libs/clipboard/clipboard.min.js"></script>
<script src="01_journal_submission_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="01_journal_submission_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="01_journal_submission_files/libs/quarto-html/popper.min.js"></script>
<script src="01_journal_submission_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="01_journal_submission_files/libs/quarto-html/anchor.min.js"></script>
<link href="01_journal_submission_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="01_journal_submission_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="01_journal_submission_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="01_journal_submission_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="01_journal_submission_files/libs/bootstrap/bootstrap-2a25cbd62610a3c84ccedb4cbacd8c09.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="01_journal_submission_files/libs/kePrint-0.0.1/kePrint.js"></script>
<link href="01_journal_submission_files/libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Effects of COVID-19 on the Academic Performance of College Students</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Aman Desai<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 23, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    I analyze the impact of the COVID-19 pandemic on undergraduates’ performance in an introductory economics course at a large public university. One challenge in analyzing student academic outcomes during the pandemic was the explicit change in grading policies by college administrators as well as the implicit adjustment by faculty designed to mitigate the impact of an abrupt shift to online learning amidst the stress and uncertainly associated with the pandemic. To limit the impact of grading policies I analyze changes in the raw scores on a common final administered to all sections of the course the year before and for four semesters after the spring of 2020. To limit variation in the difficulty of the exams from before to during the pandemic, I compare student performance on nearly identical questions on the final exam overtime. Adjusted mean scores on the common final fell by a point and the probability of answering the qualitatively same question on the final fell, on average, by 1.5 percentage points. Students with lower GPAs were 3.3 percentage points (or 0.02 standard deviations) less likely to answer similar questions correctly relative to students with higher GPAs during the pandemic. Also, the mean probability of answering a nearly identical question before and after suddenly moving to online classes increased by 5.6 percentage points.
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>COVID-19</p>
  </div>
</div>

</header>


<div style="page-break-after: always;"></div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The COVID-19 pandemic of March 2020 was disruptive across many domains, with higher education being one of them. Policies were implemented worldwide in response to this global crisis, resulting in changes in the educational setting. Educational instructions were abruptly moved online without prior preparation. This had a negative effect on primary and secondary education, leading to significant learning loss for students <span class="citation" data-cites="grewenig_covid-19_2021 fuchs-schundeln_covid-induced_2022">(<a href="#ref-grewenig_covid-19_2021" role="doc-biblioref">Grewenig et al. 2021</a>; <a href="#ref-fuchs-schundeln_covid-induced_2022" role="doc-biblioref">Fuchs-Schündeln 2022</a>)</span>.</p>
<p>Although the socioeconomic consequences of COVID-19 have been extensively studied from various perspectives, research on the impact of the pandemic on college students remains limited and yields conflicting results. Most studies examining the impact of the pandemic on students’ academic performance measure outcomes such as GPA and course completion rates. Although useful, these measures are confounded by the numerous responses of students, faculty, and administrators during the pandemic. For example, cheating became a challenging issue in the rapid move to online teaching <span class="citation" data-cites="ives_did_2024 jenkins_when_2023 walsh_why_2021">(<a href="#ref-ives_did_2024" role="doc-biblioref">Ives and Cazan 2024</a>; <a href="#ref-jenkins_when_2023" role="doc-biblioref">Jenkins et al. 2023</a>; <a href="#ref-walsh_why_2021" role="doc-biblioref">Walsh et al. 2021</a>)</span>. The faculty adopted more lenient grading practices and reduced exam difficulties. Administrators altered grading policies regarding course withdrawals and pass/fail options <span class="citation" data-cites="rodriguez-planas_covid-19_2022">(<a href="#ref-rodriguez-planas_covid-19_2022" role="doc-biblioref">Rodríguez-Planas 2022</a>)</span>. These responses made comparisons with pre-pandemic test scores, or the term GPA less reliable for quantifying learning loss during the pandemic in college students.</p>
<p>I overcome these assessment and grading issues using unique exam-level data from a large public university in New York City. First, I analyze students’ performance on final exams before and during the pandemic in an <em>introductory microeconomics</em> course. Approximately 800 students across ten sections of the course attempted a common final exam each semester. This reduces the variation in the difficulty of exams across sections. However, the difficulty of an exam may have changed in response to the pandemic. Thus, I compare students’ performance on specific exam questions that were qualitatively almost identical before and during the pandemic by matching questions from answer sheets from the common final exams before and during the pandemic. By focusing on students’ performance on nearly identical questions before and during the pandemic, I remove the variation in outcomes due to possible changes in the difficulty of these exams during the pandemic. By combining the matched question-level data with student characteristics, I estimated how the pandemic affected students’ average probability of correctly answering similar questions from pre-pandemic common exams during the crisis.</p>
<p>I begin with a before and after analysis, adjusting for student characteristics, time periods, and instructor fixed effects. I argue that more capable students are more likely to adjust to online instruction more effectively. Thus, I used a difference-in-difference design and compared students with pre-course GPA above (high GPA) and below (low GPA) the median before and during the pandemic. I observed that during the pandemic, low-GPA students were less likely to answer qualitatively similar questions from the pre-pandemic exams relative to students with higher GPAs. My analysis of dynamic effects reveals that by spring 2022, the performance gap persisted between low and high GPA students, both in overall exam scores and in their likelihood of correctly answering nearly identical questions compared with pre-pandemic levels.</p>
<p>I also analyzed the students’ performance on matched questions by difficulty level. I found no statistically significant impact of the pandemic on low GPA students’ average probability of answering nearly identical “easy” questions correctly, but I found significant effect on their performance with nearly identical <em>hard</em> questions. I also provide a similar analysis comparing outcomes between students enrolled in online and hybrid classes. My findings align with existing research on learning loss during this period. By analyzing the performance of qualitatively similar exam questions before and during the pandemic, I contribute to the literature by offering more reliable estimates of learning loss compared to traditional metrics, such as GPA and course withdrawals.</p>
<p>The next section reviews the current literature on the effects of the pandemic on college students’ academic outcomes. Section 3 discusses the data, section 4 explains the estimation strategy, section 5 reports the results, and section 6 concludes the paper.</p>
</section>
<section id="literature-review" class="level1">
<h1>Literature Review</h1>
<p>Most early studies analyzing the impact of COVID-19 on undergraduate student outcomes were based on surveys about their experiences during the pandemic. <span class="citation" data-cites="jaeger_global_2021">Jaeger et al. (<a href="#ref-jaeger_global_2021" role="doc-biblioref">2021</a>)</span> was the first to document the negative impact of the COVID-19 pandemic using surveys administered to university students in 28 universities in the United States, Spain, Australia, Sweden, Austria, Italy, and Mexico between April and October 2020. Their preliminary results reported disparate impacts on different socio-economic and demographic groups. <span class="citation" data-cites="aucejo_impact_2020">Aucejo et al. (<a href="#ref-aucejo_impact_2020" role="doc-biblioref">2020</a>)</span>, one of the first papers studying the effect of COVID-19 on college student outcomes, surveyed 1,500 students at a large public university in the United States. They found significant negative effects of the pandemic on student outcomes. Due to the pandemic, 13% of students delayed graduation, 40% lost a job, internship, or offer, and 29% expected an earnings loss by age 35. They also found large disparate impacts of the pandemic across socio-economic statuses. Lower-income students were 55% more likely than their higher-income peers to have delayed graduation due to COVID-19.</p>
<p>Along the same lines, <span class="citation" data-cites="rodriguez-planas_hitting_2020">Rodríguez-Planas (<a href="#ref-rodriguez-planas_hitting_2020" role="doc-biblioref">2020</a>)</span> collected data on students’ experiences during the pandemic using an online survey at an urban public college in New York City in the summer of 2020. The author found significant disruptions in students’ lives due to the pandemic. Because of COVID, between 14% and 34% of students considered dropping a class during spring 2020, 30% modified their graduation plans, and the freshman fall retention rate dropped by 26%. The pandemic also deprived 39% of students of their jobs, reduced the earnings of 35%, and decreased the expected household income of 64%. Pell grant recipients (students from lower-income families) were 20% more likely to lose a job due to the pandemic and 17% more likely to experience earning losses than non-Pell recipients. Other vulnerable groups, such as first-generation and transfer students, were relatively more affected. Since they seem to rely less on financial aid and more on income from wage and salary jobs, both their educational and employment outcomes were more negatively impacted by the pandemic compared to students whose parents also attended college or those who began college as freshmen.</p>
<p>The pandemic’s impact on student learning was largely driven by the sudden shift to remote instruction. Literature on remote learning shows various approaches including fully remote, software-assisted, and hybrid learning<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. While online learning offers cost benefits and wider accessibility, research indicates mixed results. Studies using randomized trials found that students in remote formats generally performed worse than those in traditional settings (<span class="citation" data-cites="joyce_does_2015">Joyce et al. (<a href="#ref-joyce_does_2015" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="alpert_randomized_2016">Alpert, Couch, and Harmon (<a href="#ref-alpert_randomized_2016" role="doc-biblioref">2016</a>)</span>). <span class="citation" data-cites="bettinger_virtual_2017">Bettinger et al. (<a href="#ref-bettinger_virtual_2017" role="doc-biblioref">2017</a>)</span> and <span class="citation" data-cites="cacault_distance_2021">Cacault et al. (<a href="#ref-cacault_distance_2021" role="doc-biblioref">2021</a>)</span> found that online learning particularly disadvantaged lower-performing students. Multiple analyses have demonstrated that online courses lead to lower completion rates, grades, and persistence <span class="citation" data-cites="jaggars_how_2016 xu_promises_2019">(<a href="#ref-jaggars_how_2016" role="doc-biblioref">Jaggars and Xu 2016</a>; <a href="#ref-xu_promises_2019" role="doc-biblioref">Xu and Xu 2019</a>)</span>.</p>
<p>Several studies attempt to use the pandemic as an exogenous shock to measure the impact of remote learning on college students’ outcomes. For instance, in their study, <span class="citation" data-cites="altindag_is_2021">Altindag, Filiz, and Tekin (<a href="#ref-altindag_is_2021" role="doc-biblioref">2021</a>)</span> analyzed administrative data from a public university and employed a fixed effects model. They examine the effect of the change in learning modality due to the pandemic on students’ learning outcomes. They found that the online instruction mode led to lower grades and an increased likelihood of course withdrawal. Students who have had greater exposure to in-person instruction have a lower likelihood of course repetition, a higher probability of graduating on time, and achieving a higher graduation GPA. Additionally, they observed that the difference in student performance between in-person and online courses tended to diminish over time in the post-pandemic era.</p>
<p>In the fall of 2020, <span class="citation" data-cites="kofoed_zooming_2021">Kofoed et al. (<a href="#ref-kofoed_zooming_2021" role="doc-biblioref">2021</a>)</span> randomized 551 West Point students in a required introductory economics course across twelve instructors into either an online or in-person class. They found that final grades for online students dropped by 0.215 standard deviations. This result was apparent in both assignments and exams and was largest for academically at-risk students. Additionally, using a post-course survey, they found that online students struggled to concentrate in class and felt less connected to their instructors and peers. They conclude that the shift to online education had negative effects on learning. Using data on Virginia community college students, <span class="citation" data-cites="bird_negative_2022">Bird, Castleman, and Lohner (<a href="#ref-bird_negative_2022" role="doc-biblioref">2022</a>)</span> applied a difference-in-differences research design leveraging instructor fixed effects and student fixed effects to estimate the impact of the transition to online learning due to the pandemic. Their results show a modest negative impact of 3% - 6% on course completion. Additionally, their findings suggest that faculty experience in delivering online lectures does not mitigate the negative effects. In their exploratory analyses, they find minimal long-term effects of the switch to online learning.</p>
<p>A comprehensive study by <span class="citation" data-cites="bonacini_unraveling_2023">Bonacini, Gallo, and Patriarca (<a href="#ref-bonacini_unraveling_2023" role="doc-biblioref">2023</a>)</span>, disentangle the channels through which the pandemic affected students. They use admin data from 2018-2021 of 36,000 university students in Italy who took about 400,000 exams during this period. They examine the overall effect of the pandemic on students’ exam scores in different courses. Additionally, they explore the effect of the transition to remote learning by using COVID as an exogenous shock with a difference-in-differences design. Their findings show that during the pandemic, students performed better, with an increase in exam scores. However, the abrupt move to remote learning decreased students’ exam scores.</p>
<p>Studies using survey data on students discussed above have found a negative impact of COVID-related disruptions on academic performance. However, studies that use measured outcomes to evaluate academic performance report mixed results, especially immediately after the pandemic began <span class="citation" data-cites="bird_negative_2022 bonacini_unraveling_2023">(<a href="#ref-bird_negative_2022" role="doc-biblioref">Bird, Castleman, and Lohner 2022</a>; <a href="#ref-bonacini_unraveling_2023" role="doc-biblioref">Bonacini, Gallo, and Patriarca 2023</a>)</span>. One reason for this might be that many institutions temporarily implemented policies to reduce the burden on students during the pandemic, particularly due to the sudden transition from traditional to fully remote learning. Instructors were likely more lenient in setting exam questions and grading, and more willing to accommodate students than before the pandemic. The sudden move to remote learning could have also created more opportunities for misbehavior by students during exams. For instance, <span class="citation" data-cites="rodriguez-planas_covid-19_2022">Rodríguez-Planas (<a href="#ref-rodriguez-planas_covid-19_2022" role="doc-biblioref">2022</a>)</span>, using data from Queens College, found that lower-income students were 35 percent more likely to utilize the flexible pass/fail grading policy. While no GPA advantage is observed among top-performing lower-income students, in the absence of the flexible grading policy these students would have seen their GPA decrease by 5% relative to their pre-pandemic mean.</p>
<p>The literature has provided valuable insights into the impact of the COVID-19 pandemic on undergraduates. However, several issues remain to be addressed. Many studies rely on self-reported survey data, which may not accurately capture the true extent of learning loss <span class="citation" data-cites="aucejo_impact_2020 rodriguez-planas_hitting_2020">(<a href="#ref-aucejo_impact_2020" role="doc-biblioref">Aucejo et al. 2020</a>; <a href="#ref-rodriguez-planas_hitting_2020" role="doc-biblioref">Rodríguez-Planas 2020</a>)</span>. I identify two major limitations in these recent studies. First, using course completion rates, course GPAs, or end-of-semester GPAs to measure academic outcomes immediately after COVID-19 hit in March may not accurately reflect students’ actual learning or learning loss. Second, the pandemic-driven sudden transition to new instruction modalities likely changed assessment methods as instructors and students took time to adjust to the situation. The difficulty of exams immediately after the adjustment may not have been the same as pre-COVID exams, contributing to inaccurate measurement of learning loss. Additionally, the implementation of flexible grading policies may have biased the effect of the pandemic on course GPA or course completion rates. I contribute to the literature in two ways. To address these limitations, I analyze students’ performance on common exams before and during the pandemic. To eliminate variation due to changes in the difficulty of exams during the pandemic, I examine students’ performance on nearly identical questions from exams before and during the pandemic to measure learning loss.</p>
</section>
<section id="data" class="level1">
<h1>Data</h1>
<p>The data used in this study are derived from two primary sources, covering the years 2019–2022. Firstly, I obtain information on students’ performance in the common final exams of the <em>introductory microeconomics</em> course, offered at a large public university in New York City. It is offered every semester and taught by multiple instructors. Each year, at least 700 students enroll in the course.</p>
<p>The department offers this course in three modes. <em>Hybrid</em> classes run twice a week, with one in-person meeting and one fully remote session each week. <em>Online</em> classes are entirely remote, with lectures delivered by professors using software. In spring 2019 and fall 2019, the courses were offered in mostly hybrid mode but with one large online section. During the pandemic in fall 2020, spring 2021, fall 2021, and spring 2022, the courses were fully online and hybrid. One section in 2022 was offered in person. I do not include those students in the analyses to facilitate the comparison between the efficacy of hybrid and online learning modes. Although the course is taught by multiple instructors with different instruction modalities, all students enrolled in the course are required to take a common final exam. Using students’ performance in these common exams removes the variation in the difficulty of questions set by the instructors. These exams are multiple choice, and the maximum possible points are 40. I obtain the answer sheets of the students who attempted these exams with information on their final score, their performance on each question, the course instructors, and learning mode of the course.</p>
<p>I use two outcomes to measure students’ academic performance. First, I use their scores on common final exams with maximum 40 possible points. This is a better measure of performance than course GPA or course completion rate since during the pandemic, a flexible grading policy was adopted. According to the university policy, students were allowed to drop the course on the last day of the semester after attempting the final exam or take the course for credit and move to the next semester. I also look at a more granular level. Since the final exams in <em>introductory microeconomics</em> are common, I can match nearly identical questions from these exams conducted before and during the pandemic. The answer sheet contains both the questions and their corresponding answers provided by the students. By analyzing the answer sheet, I am able to determine whether a student has answered a question correctly. The department would offer both hybrid and online course before the pandemic hit in March 2020. There are two versions of the exams taken by the students. The only difference between the versions is that the questions are ordered differently to reduce cheating. To facilitate the comparison, I have manually matched pairs of same or similar questions from the final exams before and after the onset of the pandemic<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. I could not obtain the data for spring 2020.</p>
<p>The second dataset is the institutional data on students who were enrolled in <em>introductory microeconomics</em> during the aforementioned semesters<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. This administrative dataset includes various information such as the students’ gender, race, age, GPA, whether they are transfer students, whether they are part-time students, their native language, and their classification (freshman, sophomore, junior, or senior). By merging these two datasets, I can create a comprehensive set of data that includes both the characteristics of the students and their exams scores, with exam level characteristics also including learning modality, course instructor, semester in which the exam was taken, and the exam version. I also merge this data with the matched question level data where I identified pairs of similar questions from the common exams pre and during the pandemic. To the best of my knowledge, this dataset is the first of its kind to examine the impact of COVID-19 on student performance at such a granular level with a standardized outcome variable.</p>
<p>My analytical sample includes 4,655 students enrolled in <em>introductory microeconomics</em> course, with a total of 47,589 observations once the similar exam questions from before and after the pandemic are matched. Here, the outcome variable is <em>correct</em>, which equals 1 if a student correctly answered the question, and 0 otherwise. Each observation is a student-question pair, indicating whether the student got the answer to the question correct or not. Some observations have missing data, including missing GPA values. For the majority of students, I use their cumulative GPA prior to the start of the semester. If a student’s cumulative GPA before the semester’s start is unavailable, I substitute it with the GPA calculated at the end of that semester. If both values are unavailable, I impute it with the mean GPA from their respective semester.</p>
</section>
<section id="estimation-strategy" class="level1">
<h1>Estimation Strategy</h1>
<p>I analyze students’ performance using multiple outcomes. I first look at their scores in the common final exam in <em>introductory microeconomics</em>. I then use their performance on matched questions from these common final exams.</p>
<p>The baseline specification is as follows:</p>
<p><span class="math display">\[
y_{i,c,t} = \delta P_{t} + \beta X_{i,c,t} + \gamma_{c} + \alpha_{s} + \epsilon_{i,c,t}
\]</span></p>
<p><span class="math inline">\(X_{i,c,t}\)</span> is the vector of individual-level controls that include students’ demographic characteristics such as race and gender. Student’s race and gender enter the specification as dummy variables. I include dummies for each race: Black, Asian, non-White Hispanic, and others, keeping White as the benchmark category. A dummy variable for gender is labeled as female, which is 1 if a student is female and 0 if male. There is also a dummy variable for being at most a sophomore student to account for where students are in the path of completing their degree. To account for student ability I control for their cumulative GPA before the start of the semester in which the students were enrolled in the course.</p>
<p><span class="math inline">\(P_{t}\)</span> is a dummy variable for the pandemic period, which is 1 for the exam taken in pandemic period and zero otherwise. Since the pandemic hit in March 2020, all the semesters after fall 2019 are considered to be in the pandemic period. <span class="math inline">\(\epsilon_{i,c,t}\)</span> is the error term. The coefficient on <span class="math inline">\(P_{t}\)</span> is of my interest which reflects the effect of the pandemic on student performance as documented by the most studies in the literature mentioned above.</p>
<p>As stated earlier, there are multiple outcome variables by which I measure student performance. In one set of regressions, y is student i score in the common final exam out if possible 40. In the other, y is a binary outcome variable which is 1 if the student answered the question correctly and 0 otherwise. Both sets of regressions are estimated using OLS and heteroskedasticity robust standard errors are used.</p>
<p><span class="math inline">\(y_{i,c,t}\)</span> is the student academic outcome for which I use multiple measures. The first set of regressions takes outcome as points scored by the students in the common final exam out of total possible 40 points. In the second set of regressions I use the matched question pairs from the common exams in the course pre and post pandemic period. Hence, this set of regressions will have a binary outcome which is 1 if a student answers the question correctly and 0 otherwise. Using OLS to estimate this linear probability model, I can see the impact of the pandemic on the average probability of students answering a similar question in pandemic period common exams compared to pre-pandemic common exams. The baseline specification will change slightly for this outcome as follows.</p>
<p><span class="math display">\[
y_{i,c,q,t} = \delta P_{t} + \beta X_{i,c,q,t} + \gamma_{c} + \alpha_{s} + \epsilon_{i,c,q,t}
\]</span></p>
<p><span class="math inline">\(y_{i,c,q,t}\)</span> will be the student i’s outcome in question q in a class taught by instructor c in semester t. All the control variables on the right hand side will remain the same as described in the first specification. <span class="math inline">\(\gamma_{c}\)</span> in both versions of the baseline specification is instructor fixed effects. <span class="math inline">\(\alpha_{s}\)</span> in both specifications is session fixed effects.</p>
<section id="identification-of-differential-impact-of-covid-on-low-vs-high-gpa-students" class="level2">
<h2 class="anchored" data-anchor-id="identification-of-differential-impact-of-covid-on-low-vs-high-gpa-students">Identification of differential impact of COVID on low vs high GPA students</h2>
<p>I also take a closer look at the differential impact of the pandemic on students with low GPA compared to high GPA students. I define low GPA students using a cutoff based on the median cumulative GPA. Students with a GPA less than the median GPA of 3.32 are classified as low GPA students, and those with a GPA of 3.32 or higher are classified as high GPA students.</p>
<p>The regression specification builds on the baseline specification in equation 1. For both outcomes, exam scores and question-level outcomes, the specification remains similar. The following is the specification for exam scores as the outcome variable.</p>
<p><span class="math display">\[
y_{i,c,t} = \delta P_{t} + \phi L_{i} + \mu P_{t} \times L_{i} + \beta X_{i,c,t} + \gamma_{c} + \alpha_{s} + \epsilon_{i,c,t}
\]</span></p>
<p>Here, variable <span class="math inline">\(L_{i}\)</span> is a dummy variable representing students in the low GPA group. <span class="math inline">\(L_{i}\)</span> takes a value of 1 if a student is in the low GPA group and 0 if a student is in the high GPA group. <span class="math inline">\(\mu\)</span> is the coefficient in which I am interested. A negative value of this coefficient will support the hypothesis of higher learning loss during the pandemic for low GPA students compared to high GPA students. Instructor and session fixed effects are included. All the included student-level covariates are the same as in equation 1, except for cumulative GPA.</p>
</section>
<section id="identification-of-the-effect-of-sudden-transition-to-remote-learning" class="level2">
<h2 class="anchored" data-anchor-id="identification-of-the-effect-of-sudden-transition-to-remote-learning">Identification of the effect of sudden transition to remote learning</h2>
<p>So far, with all previous specifications, I can estimate the pandemic’s impact on student outcomes. The coefficients I obtain represent the overall effect of the pandemic on students’ academic performance. One main driver of the negative impact on academic performance is the sudden transition to a new learning modality. This sudden change affected both students and instructors, disrupting the learning process. I attempt to disentangle this impact of sudden change in learning modality due to the pandemic from the overall impact of the pandemic on students’ academic performance. As previously mentioned in the data section, during the time in consideration, the department of economics offered <em>introductory microeconomics</em> course to the students using two modalities. Hybrid mode that included 1 lecture in person and other online during a regular week and online classes were completely remote. Pandemic in March 2020 led to a sudden transition to online classes for all students in the course. This exogenous shock allows me to look at the impact of this sudden transition to remote learning mode during the pandemic period. I identify the impact of pandemic induced movement to remote learning by estimating a DiD specification as follows.</p>
<p><span class="math display">\[
y_{i,c,t} = \delta P_{t} + \phi O_{i} + \mu P_{t} \times O_{i} + \beta X_{i,c,t} + \gamma_{c} + \alpha_{s} + \epsilon_{i,c,t}
\]</span></p>
<p>As with the specification 3, I only show the equation for exam scores as the outcome. The specification will be the same for question-level outcome. Here, variable <span class="math inline">\(O_{i}\)</span> is a dummy variable representing students in classes with different modes of instruction. <span class="math inline">\(O_{i}\)</span> takes a value of 1 if a student is enrolled in an online class and 0 if a student is in a hybrid class. <span class="math inline">\(\mu\)</span> is the coefficient in which I am interested. A negative value of this coefficient will result in learning loss for the students during the pandemic due to an abrupt transition to remote classes. Again, instructor and session fixed effects are included. All the included student-level covariates are the same as in equation 1, except for their instruction mode.</p>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="average-course-gpa-across-semesters-in-eco-1001" class="level2">
<h2 class="anchored" data-anchor-id="average-course-gpa-across-semesters-in-eco-1001">Average Course GPA Across Semesters in ECO 1001</h2>
<p>An important argument I make in this paper is that student performance is mostly measured using course completion, withdrawal rates, or GPA in the literature currently. These may not be good measures of academic performance during the pandemic, given that most educational institutions adopted flexible grading policies to reduce the burden on students due to pandemic-related disruptions.</p>
<p>In Figure 1, I show how the unadjusted average GPA in course ECO 1001 changes over time. I see an abrupt jump in course GPA in spring 2020 when the pandemic started. According to student surveys mentioned in the literature review, students faced hardships and struggled in their studies due to the disruption in their environment. Although these GPAs decreased in fall 2020 and spring 2021, they did not return to pre-pandemic levels until after fall 2021.</p>
<p>Using course GPA as a measure of student performance contradicts students’ experiences. A sudden change in the educational setting also affected instructors, who might have become more lenient with grading. This change could have led to common exams being held online, giving students more opportunities for possible misconduct. The possible negative impact of the pandemic on students’ actual performance could be overshadowed by these changes in institutional policies and educational settings.</p>
</section>
<section id="withdrawal-rate-across-semesters-in-eco-1001" class="level2">
<h2 class="anchored" data-anchor-id="withdrawal-rate-across-semesters-in-eco-1001">Withdrawal Rate Across Semesters in ECO 1001</h2>
<p>Another possible mechanism leading to the opposing change in measured performance is that the institution in consideration, like many other academic institutions, adopted a flexible grading policy to help students face the challenges due to the pandemic. This policy aimed to reduce the burden on students by providing three options up until the last day of the semester. The first option, Credit (CR), allowed students to pass the course with credit, though their grade wouldn’t affect their GPA. The second, No Credit (NC), let students complete the course without credit, allowing them to retake it later without any record of their withdrawal. The third was the standard course withdrawal option.</p>
<p>Figure 2 shows the unadjusted withdrawal rates across semesters in ECO 1001. The course withdrawal rate decreased to 0.83% in fall 2019, down from 4.97% in spring 2019. However, it increased again to 3.92% in spring 2020, a semester heavily influenced by the onset of the pandemic. Despite the pandemic, the withdrawal rate was kept relatively low due to the introduction of a flexible grading policy by the college. As shown in the figure, 29.75% of students enrolled in ECO 1001 chose the CR option, while 5.53% chose NC. Because of this flexibility, only 3.92% of students opted for a standard withdrawal in spring 2020. The withdrawal rate increased to 6.65% in fall 2020 and remained roughly at that level, reaching around 8% in spring 2022. It is worth noting that the flexible grading policy was not implemented after spring 2020. Using course GPA or course completion rate in presence of a flexible grading policy may not give me a clear effect of the pandemic on students’ academic outcomes and their learning loss.</p>
</section>
<section id="baseline-specification" class="level2">
<h2 class="anchored" data-anchor-id="baseline-specification">Baseline Specification</h2>
<div class="cell">
<div class="cell-output-display">
<table class="table caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>Baseline Specification</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th" style="text-align: left; empty-cells: hide; border-bottom: hidden;"></th>
<th colspan="2" data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px; font-weight: bold; font-style: italic;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Final Exam Score<br>
(mean = 57.1, sd = 15.6)
</div></th>
<th colspan="2" data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px; font-weight: bold; font-style: italic;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Did Student Get The Answer Correct (Y/N)?<br>
(mean = 0.6, sd = 0.49)
</div></th>
</tr>
<tr class="even">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: center;" data-quarto-table-cell-role="th">(1)</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">(2)</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">(3)</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">(4)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">postcovid</td>
<td style="text-align: center;">-1.151</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.019***</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;">(0.744)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(0.007)</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">fall 2020</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.308</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.102***</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(1.504)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(0.013)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">spring 2021</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-5.760***</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.082***</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(1.135)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(0.015)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">fall 2021</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">5.643***</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.019**</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(1.169)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(0.010)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">spring 2022</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-6.954***</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.088***</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(1.370)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(0.012)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Num.Obs.</td>
<td style="text-align: center;">4598</td>
<td style="text-align: center;">4598</td>
<td style="text-align: center;">47589</td>
<td style="text-align: center;">47589</td>
</tr>
<tr class="even">
<td style="text-align: left;">R2</td>
<td style="text-align: center;">0.209</td>
<td style="text-align: center;">0.223</td>
<td style="text-align: center;">0.036</td>
<td style="text-align: center;">0.039</td>
</tr>
</tbody><tfoot>
<tr class="odd">
<td style="text-align: left; padding: 0;"><span style="font-style: italic;">Note: </span> <sup></sup> * p {</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tfoot>

</table>
</div>
</div>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-alpert_randomized_2016" class="csl-entry" role="listitem">
Alpert, William T., Kenneth A. Couch, and Oskar R. Harmon. 2016. <span>“A <span>Randomized</span> <span>Assessment</span> of <span>Online</span> <span>Learning</span>.”</span> <em>American Economic Review</em> 106 (5): 378–82. <a href="https://doi.org/10.1257/aer.p20161057">https://doi.org/10.1257/aer.p20161057</a>.
</div>
<div id="ref-altindag_is_2021" class="csl-entry" role="listitem">
Altindag, Duha Tore, Elif S. Filiz, and Erdal Tekin. 2021. <span>“Is <span>Online</span> <span>Education</span> <span>Working</span>?”</span> Working {Paper}. Working <span>Paper</span> <span>Series</span>. National Bureau of Economic Research. <a href="https://doi.org/10.3386/w29113">https://doi.org/10.3386/w29113</a>.
</div>
<div id="ref-aucejo_impact_2020" class="csl-entry" role="listitem">
Aucejo, Esteban M., Jacob French, Maria Paola Ugalde Araya, and Basit Zafar. 2020. <span>“The Impact of <span>COVID</span>-19 on Student Experiences and Expectations: <span>Evidence</span> from a Survey.”</span> <em>Journal of Public Economics</em> 191 (November): 104271. <a href="https://doi.org/10.1016/j.jpubeco.2020.104271">https://doi.org/10.1016/j.jpubeco.2020.104271</a>.
</div>
<div id="ref-bettinger_virtual_2017" class="csl-entry" role="listitem">
Bettinger, Eric P., Lindsay Fox, Susanna Loeb, and Eric S. Taylor. 2017. <span>“Virtual <span>Classrooms</span>: <span>How</span> <span>Online</span> <span>College</span> <span>Courses</span> <span>Affect</span> <span>Student</span> <span>Success</span>.”</span> <em>American Economic Review</em> 107 (9): 2855–75. <a href="https://doi.org/10.1257/aer.20151193">https://doi.org/10.1257/aer.20151193</a>.
</div>
<div id="ref-bird_negative_2022" class="csl-entry" role="listitem">
Bird, Kelli A., Benjamin L. Castleman, and Gabrielle Lohner. 2022. <span>“Negative <span>Impacts</span> from the <span>Shift</span> to <span>Online</span> <span>Learning</span> During the <span>COVID</span>-19 <span>Crisis</span>: <span>Evidence</span> from a <span>Statewide</span> <span>Community</span> <span>College</span> <span>System</span>.”</span> <em>AERA Open</em> 8 (1). <a href="https://doi.org/10.1177/23328584221081220">https://doi.org/10.1177/23328584221081220</a>.
</div>
<div id="ref-bonacini_unraveling_2023" class="csl-entry" role="listitem">
Bonacini, Luca, Giovanni Gallo, and Fabrizio Patriarca. 2023. <span>“Unraveling the Controversial Effect of <span>Covid</span>-19 on College Students’ Performance.”</span> <em>Scientific Reports</em> 13 (1): 15912. <a href="https://doi.org/10.1038/s41598-023-42814-7">https://doi.org/10.1038/s41598-023-42814-7</a>.
</div>
<div id="ref-cacault_distance_2021" class="csl-entry" role="listitem">
Cacault, M Paula, Christian Hildebrand, Jérémy Laurent-Lucchetti, and Michele Pellizzari. 2021. <span>“Distance <span>Learning</span> in <span>Higher</span> <span>Education</span>: <span>Evidence</span> from a <span>Randomized</span> <span>Experiment</span>.”</span> <em>Journal of the European Economic Association</em> 19 (4): 2322–72. <a href="https://doi.org/10.1093/jeea/jvaa060">https://doi.org/10.1093/jeea/jvaa060</a>.
</div>
<div id="ref-escueta_education_2017" class="csl-entry" role="listitem">
Escueta, Maya, Vincent Quan, Andre Joshua Nickow, and Philip Oreopoulos. 2017. <span>“Education <span>Technology</span>: <span>An</span> <span>Evidence</span>-<span>Based</span> <span>Review</span>,”</span> August, w23744. <a href="https://doi.org/10.3386/w23744">https://doi.org/10.3386/w23744</a>.
</div>
<div id="ref-fuchs-schundeln_covid-induced_2022" class="csl-entry" role="listitem">
Fuchs-Schündeln, Nicola. 2022. <span>“Covid-<span>Induced</span> <span>School</span> <span>Closures</span> in the <span>US</span> and <span>Germany</span>: <span>Long</span>-<span>Term</span> <span>Distributional</span> <span>Effects</span>.”</span> <em>CESifo Working Paper Series</em>. <a href="https://ideas.repec.org//p/ces/ceswps/_9698.html">https://ideas.repec.org//p/ces/ceswps/_9698.html</a>.
</div>
<div id="ref-grewenig_covid-19_2021" class="csl-entry" role="listitem">
Grewenig, Elisabeth, Philipp Lergetporer, Katharina Werner, Ludger Woessmann, and Larissa Zierow. 2021. <span>“<span>COVID</span>-19 and Educational Inequality: <span>How</span> School Closures Affect Low- and High-Achieving Students.”</span> <em>European Economic Review</em> 140 (November): 103920. <a href="https://doi.org/10.1016/j.euroecorev.2021.103920">https://doi.org/10.1016/j.euroecorev.2021.103920</a>.
</div>
<div id="ref-ives_did_2024" class="csl-entry" role="listitem">
Ives, Bob, and Ana-Maria Cazan. 2024. <span>“Did the <span>COVID</span>-19 Pandemic Lead to an Increase in Academic Misconduct in Higher Education?”</span> <em>Higher Education</em> 87 (1): 111–29. <a href="https://doi.org/10.1007/s10734-023-00996-z">https://doi.org/10.1007/s10734-023-00996-z</a>.
</div>
<div id="ref-jaeger_global_2021" class="csl-entry" role="listitem">
Jaeger, David A., Jaime Arellano-Bover, Krzysztof Karbownik, Marta Martínez Matute, John M. Nunley, Jr Seals, Miguel Almunia, et al. 2021. <span>“The <span>Global</span> <span>COVID</span>-19 <span>Student</span> <span>Survey</span>: <span>First</span> <span>Wave</span> <span>Results</span>.”</span> Working {Paper} 14419. IZA Discussion Papers. <a href="https://www.econstor.eu/handle/10419/236450">https://www.econstor.eu/handle/10419/236450</a>.
</div>
<div id="ref-jaggars_how_2016" class="csl-entry" role="listitem">
Jaggars, Shanna Smith, and Di Xu. 2016. <span>“How Do Online Course Design Features Influence Student Performance?”</span> <em>Computers &amp; Education</em> 95 (April): 270–84. <a href="https://doi.org/10.1016/j.compedu.2016.01.014">https://doi.org/10.1016/j.compedu.2016.01.014</a>.
</div>
<div id="ref-jenkins_when_2023" class="csl-entry" role="listitem">
Jenkins, Baylee D., Jonathan M. Golding, Alexis M. Le Grand, Mary M. Levi, and Andrea M. Pals. 2023. <span>“When <span>Opportunity</span> <span>Knocks</span>: <span>College</span> <span>Students</span>’ <span>Cheating</span> <span>Amid</span> the <span>COVID</span>-19 <span>Pandemic</span>.”</span> <em>Teaching of Psychology</em> 50 (4): 407–19. <a href="https://doi.org/10.1177/00986283211059067">https://doi.org/10.1177/00986283211059067</a>.
</div>
<div id="ref-joyce_does_2015" class="csl-entry" role="listitem">
Joyce, Ted, Sean Crockett, David A. Jaeger, Onur Altindag, and Stephen D. O’Connell. 2015. <span>“Does Classroom Time Matter?”</span> <em>Economics of Education Review</em> 46 (June): 64–77. <a href="https://doi.org/10.1016/j.econedurev.2015.02.007">https://doi.org/10.1016/j.econedurev.2015.02.007</a>.
</div>
<div id="ref-kofoed_zooming_2021" class="csl-entry" role="listitem">
Kofoed, Michael S., Lucas Gebhart, Dallas Gilmore, and Ryan Moschitto. 2021. <span>“Zooming to <span>Class</span>?: <span>Experimental</span> <span>Evidence</span> on <span>College</span> <span>Students</span>’ <span>Online</span> <span>Learning</span> During <span>COVID</span>-19.”</span> <a href="https://www.iza.org/publications/dp/14356/zooming-to-class-experimental-evidence-on-college-students-online-learning-during-covid-19">https://www.iza.org/publications/dp/14356/zooming-to-class-experimental-evidence-on-college-students-online-learning-during-covid-19</a>.
</div>
<div id="ref-rodriguez-planas_hitting_2020" class="csl-entry" role="listitem">
Rodríguez-Planas, Núria. 2020. <span>“Hitting <span>Where</span> It <span>Hurts</span> <span>Most</span>: <span>Covid</span>-19 and <span>Low</span>-<span>Income</span> <span>Urban</span> <span>College</span> <span>Students</span>.”</span> {SSRN} {Scholarly} {Paper}. Rochester, NY. <a href="https://doi.org/10.2139/ssrn.3682958">https://doi.org/10.2139/ssrn.3682958</a>.
</div>
<div id="ref-rodriguez-planas_covid-19_2022" class="csl-entry" role="listitem">
———. 2022. <span>“<span>COVID</span>-19, College Academic Performance, and the Flexible Grading Policy: <span>A</span> Longitudinal Analysis.”</span> <em>Journal of Public Economics</em> 207 (March): 104606. <a href="https://doi.org/10.1016/j.jpubeco.2022.104606">https://doi.org/10.1016/j.jpubeco.2022.104606</a>.
</div>
<div id="ref-walsh_why_2021" class="csl-entry" role="listitem">
Walsh, Lisa L., Deborah A. Lichti, Christina M. Zambrano-Varghese, Ashish D. Borgaonkar, Jaskirat S. Sodhi, Swapnil Moon, Emma R. Wester, and Kristine L. Callis-Duehl. 2021. <span>“Why and How Science Students in the <span>United</span> <span>States</span> Think Their Peers Cheat More Frequently Online: Perspectives During the <span>COVID</span>-19 Pandemic.”</span> <em>International Journal for Educational Integrity</em> 17 (1): 1–18. <a href="https://doi.org/10.1007/s40979-021-00089-3">https://doi.org/10.1007/s40979-021-00089-3</a>.
</div>
<div id="ref-xu_promises_2019" class="csl-entry" role="listitem">
Xu, Di, and Ying Xu. 2019. <span>“The <span>Promises</span> and <span>Limits</span> of <span>Online</span> <span>Higher</span> <span>Education</span>: <span>Understanding</span> <span>How</span> <span>Distance</span> <span>Education</span> <span>Affects</span> <span>Access</span>, <span>Cost</span>, and <span>Quality</span>.”</span> American Enterprise Institute. <a href="https://eric.ed.gov/?id=ED596296">https://eric.ed.gov/?id=ED596296</a>.
</div>
</div>
<div style="page-break-after: always;"></div>
</section>
<section id="appendix" class="level1">
<h1>Appendix</h1>
<section id="average-final-exam-scores-in-eco-1001-across-semesters" class="level2">
<h2 class="anchored" data-anchor-id="average-final-exam-scores-in-eco-1001-across-semesters">Average final exam scores in ECO 1001 across semesters</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_journal_submission_files/figure-html/exam-scores-mean-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Average Final Exam Scores in ECO 1001 across Semesters</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="student-shares-in-low-and-high-gpa-groups" class="level2">
<h2 class="anchored" data-anchor-id="student-shares-in-low-and-high-gpa-groups">Student shares in low and high GPA groups</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_journal_submission_files/figure-html/share-gpa-low-high-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Share of High vs Low GPA Students</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="average-gpa-in-low-and-high-gpa-groups-in-eco-1001-across-semesters" class="level2">
<h2 class="anchored" data-anchor-id="average-gpa-in-low-and-high-gpa-groups-in-eco-1001-across-semesters">Average GPA in low and high GPA groups in ECO 1001 across semesters</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_journal_submission_files/figure-html/meangpa-gpa-group-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Average GPA in High vs Low GPA Group of Students</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="share-of-students-in-hybrid-and-online-classes" class="level2">
<h2 class="anchored" data-anchor-id="share-of-students-in-hybrid-and-online-classes">Share of Students in hybrid and online classes</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_journal_submission_files/figure-html/student-share-online-hybrid-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Share of the Students in Hybrid vs Online Classes</figcaption>
</figure>
</div>
</div>
</div>
<div style="page-break-after: always;"></div>
</section>
<section id="example-of-a-matched-question" class="level2">
<h2 class="anchored" data-anchor-id="example-of-a-matched-question">Example of a Matched-Question</h2>
<p>As explained earlier, I were able to match 35 pairs of nearly identical questions from pre-pandemic common exams to exams conducted during the pandemic. I provide an example of one such question below that was similar in common final exams in fall 2019 and fall 2020 which was deemed to be <em>hard</em> by the instructors. Full list of matched questions are provided in a separate document.</p>
<section id="fall-2019-version" class="level3">
<h3 class="anchored" data-anchor-id="fall-2019-version">Fall 2019 version</h3>
<p>Scenario 2, Monopoly: Let the following equations the market for energy for ConEd, a monopolist: <span class="math inline">\(P=56-2Q\)</span>, <span class="math inline">\(MR=56-4Q\)</span>, <span class="math inline">\(TC=50+6Q+3Q^2\)</span>, <span class="math inline">\(MC=6+6Q\)</span></p>
<p>Refer to Scenario 2, Monopoly: What is the profit of ConEd at the profit maximizing quantity? (round to the nearest whole number and pick the best answer)</p>
<ol type="a">
<li>100</li>
<li>50</li>
<li>75</li>
<li>155</li>
</ol>
</section>
<section id="fall-2020-version" class="level3">
<h3 class="anchored" data-anchor-id="fall-2020-version">Fall 2020 version</h3>
<p>A monopolist has a total cost curve represented by <span class="math inline">\(TC=50+2Q+Q^2\)</span>, and a marginal cost curve represented by <span class="math inline">\(MC=2+2Q\)</span>. The monopolist faces the demand curve <span class="math inline">\(P=100-3Q\)</span>. The price is in dollars and the quantity is in thousands. What is the monopolist’s profit? (pick the closest answer)</p>
<ol type="a">
<li>$330,330</li>
<li>$550,250</li>
<li>$750,000</li>
<li>$1,000,600</li>
</ol>
</section>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>CUNY Graduate Center<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>CUNY Graduate Center<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>CUNY Graduate Center<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>see <span class="citation" data-cites="escueta_education_2017">Escueta et al. (<a href="#ref-escueta_education_2017" role="doc-biblioref">2017</a>)</span> for a comprehensive review.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>35 unique pairs of question are matched from before and after pandemic common exams. The questions are provided in a separate document.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>The Baruch Office of Research and Compliance, Re:[2020-0621]&nbsp;Collecting Baseline Data on Distance Learning Performance, was determined not human subject research as there was no contact with subjects and data were de-identified.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>